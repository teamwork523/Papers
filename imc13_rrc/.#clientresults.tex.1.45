\section{RRC inference results}\label{sec:clientresults}

We will start by describing our findings using our client-based RRC inference approach in controlled, local experiments, and then describe how we used QxDM-based cross-layer analysis to verify our findings and investigate root causes of our observed findings.  Then, in \S\ref{sec:largescalestudy} we will describe the results of the public deployment of our inference tool to examine how representative the trends and behavior we discovered are of RRC states worldwide.

%We took two main types of RRC inference-related measurements.  First, we took measurements in a controlled setting, using a set of custom RRC inference tools. There were two main components of these tests that we describe below:  a controlled deployment within T-mobile of our client-based inference tool on experimental devices, and a set of experiments on local devices requiring QxDM analysis.  Our preliminary tests to develop the RRC inference algorithm were described in \S\ref{sec:stateinferencemethodology} and we do not repeat them here.

%Second, we also deployed a pared-down version of our coarse-grained timer inference tool in order to understand global trends in RRC state machine behavior. The most important difference between that tool and our internal tool is that our internal tool will always perform a complete set of tests, whereas the widely-distributed version may take an incomplete set of measurements if there is a loss of cellular connectivity (for example, if the device switches to WiFi.) These tests allow us to understand trends in RRC state implementations and performance around the world, and how they differ by carrier, device model and network technology.We describe the results of these tests in \S\ref{sec:largescalestudy}.

%\comment{TODO update all measured Mobiperf/Tmobiperf values - how long can I wait?}


\subsection{Results of Controlled Experiments}

We collected three types of data from our controlled experiments: results from a small number of test devices on various carriers, in order to develop and validate our analysis methodology; results from a deployment within T-mobile, to measure RRC states and performance characteristics; and QxDM traces to validate our T-mobile results and investigate root causes of the phenomena we detected.  The results of our first set of tests were confirmed with power monitor measurements as well as through discussions with T-Mobile to verify our findings.  We will primarily discuss the other two sets of results here.

Using our internal deployment, we found that the timers and state machines were consistent for devices in several locations across the US.  We focused primarily on measuring demotion timers and performance in each RRC state. For LTE, we found a timer of 2s to transition from the high-power to low-power state.  For UMTS, we found a 2.5s timer to demote to FACH and another 2.5s timer to demote to PCH, and also detected a period of high latency when demoting from DCH to FACH, lasting from 1 to 2.5s --- in other words, in some cases, this phenomena prevented any performance gains from using FACH.  There were a small number of devices on an EDGE network, from which we detected a demotion timer of 1.5s between the low-power and high-power state, with no intermediate state detected.  A single device on HSDPA had a timer of 3s to demote to the low-power state, also with no intermediate state.

%There is a second RRC state machine deployed in some locations for 3G that we did not detect. %\comment{ARe the two state machines for two different technologies?}

The latency increase when demoting from DCH to FACH for UMTS was of particular interest.  A similar pattern was occasionally seen when demoting to DCH, but was generally no more than half a second in length.   Likewise, this delay sometimes occurred in LTE when demoting to RRC\_{}CONNECTED. An example can be seen in Figure~\ref{fig:rtt_raw_data_22}.  This delay is of particular concern because the associated RTTs are often significantly longereven than those in PCH; it is as though during these transitions data transmissions are simply paused for a second or more.  In some cases, the user derives no benefit from FACH at all, as this phenomenon lasts long enough that the expected FACH behavior is never observed.  Given that the purpose of FACH is to provide lower latency for small packets than in PCH, at the expense of increased power consumption, this phenomenon has a significant negative impact on performance.

Figure~\ref{fig:network_tech_compare} summarizes the difference between UDP RTTs for different RRC states.  We classify DCH and RRC\_CONNECTED, for 3G and 4G technologies, as high power; IDLE and RRC\_IDLE as low-power, and FACH as medium-power.  The RTT spike when transitioning from DCH to FACH is indicated as "transition", and for this carrier occured only for UMTS. No error bars are shown for HSDPA since we only have one set of measurements for this technology.  

In general, performance improves slightly for newer technologies, especially when going from DCH to FACH. Consistent with previous work~\cite{4g_rrc}, improvements in latency between LTE and 3G technologies are not dramatic. It was found in previous work that is mostly bandwidth where LTE benefits, and the largest improvements are in the low-power state for large packets, albeit with a very high variance in our measurements.  It can be seen clearly here that the worst performance (aside from EDGE) is in the transition period between DCH and FACH, and furthermore that the average latency for small packets in FACH is not substantially better than in PCH.


\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.45\textwidth]{figs/network_tech_compare.png}
\end{center}
\ncaption{Performance of Various Network Technologies for a Single Carrier (T-mobile)}
\label{fig:network_tech_compare}
\end{figure}

We examined the impact of RRC state on several higher-level protocols.  We investigated the time to complete a DNS lookup, a TCP handshake, and the loading of a small webpage over HTTP.  For the DNS test, we generated a random, invalid URL, as we found that on some of our devices we could not reliably flush the DNS cache.  For TCP, we measured the time to perform a TCP handshake with ``www.google.com", and we measured the time to access ``www.google.com" through HTTP.

Unsurprisingly, for TCP and DNS lookups, the latency pattern was essentially the same as for UDP.  The delay caused by RRC promotion was in these cases a significant proportion of the overall delay.  For HTTP, however, the impact of RRC state was not statistically significant.  This is also relatively unsurprising, as the RRC state will only affect the first packet sent.  RRC state will primarily impact frequent, low-bandwidth transmissions, such as applications that perform periodic polling, as suggested in previous work~\cite{aro}.

%\begin{figure}
%\begin{center}
%\includegraphics[width=0.45\textwidth]{figs/extra_tests.png}
%\end{center}
%\ncaption{Impact of RRC state on non-UDP protocols}
%\label{fig:extra_tests}
%\end{figure}


\subsubsection{Cross-Layer Root-Cause Analysis with QxDM}\label{sec:qxdm.analysis}
We examine the root cause of these unexpected latencies when transitioning between RRC states by making use of results from \emph{QxDM\_{}UDP\_{}Trace} and \emph{QxDM\_{}TCP\_{}Trace}, and in \S\ref{sec:eval} we propose an approach to avoid these unexpected latencies.  We also identify the prevalence and root causes of UDP packet losses. In this section, we make use of terminology defined in \ref{sec:background}.  Based on our measurements of the FACH and PCH promotion times, we consider FACH\_{}PROMOTE to cover the time 0.92 seconds before DCH promotion occurs in \emph{QxDM\_{}UDP\_{}Trace} and \emph{QxDM\_{}TCP\_{}Trace}, and similarly PCH\_{}PROMOTE covers the time 0.21 seconds before FACH promotion occurs.

%We identify the root cause of unexpected latencies by making use of results from a set of QxDM measurements that we will refer to as \emph{QxDM\_{}Trace}.  We propose in \S\ref{sec:eval} an approach to avoid these unexpected latencies.  Next, we use \emph{QxDM\_{}Trace} to identify the prevalence and root causes of UDP packet losses.  

%\S~\ref{sec:root.cause.analysis} identifies the root cause of latency by results from both emph{QxDM\_{}Trace}, and propose RLC Fast retransmission mechanism to reduce the RLC delay. \S~\ref{sec:udp.loss.analysis} is a case study of utilizing the cross layer mapping and retransmission calculation technique to identify the root cause of the UDP packet loss.
%\subsection{Cross Layer Analysis with QxDM}\label{sec:qxdm.analysis}
%\S~ref{sec:rrc.term} defines and highlights subset of FACH state so that we could have fine grained understanding the abnormal latency issue. \S~\ref{sec:root.cause.analysis} identifies the root cause of latency by results from both emph{QxDM\_{}Trace}, and propose RLC Fast retransmission mechanism to reduce the RLC delay. \S~\ref{sec:udp.loss.analysis} is a case study of utilizing the cross layer mapping and retransmission calculation technique to identify the root cause of the UDP packet loss.

%However, as at the RLC layer we can observe various phenomena that are not detectable at higher layers, we will start by defining some terminology. Because the the promotion period for PCH and FACH differs from their initial period due to additional signaling overhead, we want to distinguish between a RRC state with and without involving transitions. Since we focus on the initial period of data transmission, the RRC state promotion is more meaningful than state demotion, which is the end of whole data transmission period. So RRC state promotion is our preliminary concern for this project. We break down the normal FACH into an initial FACH state and FACH to DCH promotion state, named as FACH\_{}INIT and FACH\_{}PROMOTE specifically. Similarly, PCH was divided into PCH\_{}INIT and PCH\_{}PROMOTE.

%Since the FACH promotion timer is on average 0.92 seconds and PCH promotion state is on average 0.21 seconds, we consider the time
%define the FACH\_{}PROMOTE state as the time slot of counting back 0.92 seconds from the point of promoting to DCH. For the same reason, PCH\_{}PROMOTE state describes the time slot of counting back 0.21 seconds from the point of promoting to FACH.

%\subsubsection{Root Cause of Latency}\label{sec:root.cause.analysis}
% explain why we want to calculate RLC layer retransmission and how to calculate

The prove the strong correlation between the data link layer retransmission and upper layer latency, we calculate the RLC layer retransmission ratio over each inter-packet time interval with the methodology described in \S\ref{sec:rlc.retx.cal}. We instrument the inter-packet time in the packet payload of the \emph{QxDM\_{}UDP\_{}Trace} so that we could directly correlate the RLC PDUs with that value after we apply the cross layer mapping algorithm from \S\ref{sec:cross.layer.algo}. We observe the high retransmission ratio over FACH state in Figure~\ref{fig:rlc.retx.per.gap}, matching with the latency behaviors in Figure~\ref{fig:rtt_raw_data_22}. The similar patterns implies that root cause of FACH latency issue resides in the data link layer.

\begin{figure}[t!]
\centering
\includegraphics[width=0.5\textwidth]{figs/rlc_retx_gap.eps}
\ncaption{RLC layer retransmission ratio has a strong correlation with the delay over FACH state}
\label{fig:rlc.retx.per.gap}	
\end{figure}

There are two possible RLC retransmission behaviors that lead to delay at the transport layer. First, retransmission may be necessary due to noisy channel conditions during FACH. Based on \emph{QxDM\_{}UDP\_{}Trace} and \emph{QxDM\_{}TCP\_{}Trace}, we can see that RLC retransmission ratios are particularly high during FACH state.  A possible solution is for the application to batch data transmissions to reduce the frequency of RRC state promotions, a solution that has been shown to be beneficial in eliminating other sorts of transmission-related delays~\cite{3g_rrc}.  Second, retransmissions can become unnecessarily delayed due to a slow response to PDU loss signals, i.e. duplicated ACKs. In particular, this can effect TCP transmissions, as the relationship between TCP retransmissions and RLC retransmissions leads to delays.  We propose a solution to this latter problem in \S\ref{sec:eval}.

%a strong correlation between RLC retransmission ratio and FACH state as an evidence. One possible solution is that application could batch the data transmission to reduce the RRC state promotion frequency~\cite{3g_rrc}. The second one is the retransmission get unnecessary delayed caused by the lagging response to the PDU loss signal. We also observe it from \emph{QxDM\_{}Trace} when we studied the relationship between TCP retransmission and RLC retransmission. We will also provide a improved RLC mechanism to avoid the unnecessary delay later.

% UDP trace analysis

Using the RLC retransmission calculation methodology described in \S\ref{sec:rlc.retx.cal}, we calculate the RLC transmission ratio for each state and each promotion or demotion period as shown in Figure~\ref{fig:RLC.Loss.Per.RRC.UDPTrace}. The retransmission ratios are particularly high in FACH\_{}INIT and FACH\_{}PROMOTE, and for the HTC device is especially high during FACH\_{}INIT. These observations are consistent with the abnormal delays we observed when transitioning from DCH to FACH. The higher loss rates for the HTC device are also consistent with our observation that the HTC One (and many HTC devices) exhibit this abnormal delay far more frequently than the Galaxy S3. A possible explanation is the difference in hardware used. The HTC device uses Snapdragon S3 MSM8260, while the Galaxy S3 contains the next-generation Snapdragon S4 MSM8960 and supports a larger range of network types~\cite{snapdragon}. This might also explain why this phenomenon was not observed in earlier work on older devices. However, a detailed examination of hardware differences is out of the scope of the paper.

%Analyzing the \emph{QxDM\_{}Trace} based on the RLC retransmission calculation methodology, we calculate the RLC retransmission ratio per RRC state in Figure~\ref{fig:RLC.Loss.Per.RRC.UDPTrace}. As we can see, the RLC retransmission among FACH and FACH\_{}PROMOTE in total are \textit{46.63\%} for HTC One S device with standard deviation of \textit{4.28\%}, and \textit{14.23\%} for Galaxy S3 devices with standard deviation of \textit{0.66\%}. It strongly suggested the significant delay over the FACH\_{}INIT and FACH\_{}PROMOTE states, which indicates the higher chance of RLC retransmission in a resource shared and noisy channel during FACH state. The observation is consistent with the abnormal delays during initial FACH state as we could also observe radio bearer configuration signaling and other system signaling exchange between the handset and the base station. We also observe that the HTC device has a higher loss rate than that of Galaxy S3. One possible explanation for device dependent behavior is that the difference in hardware module. The HTC One S was produced over Snapdragon S3 MSM8260, while the Galaxy S3 contains Snapdragon S4 MSM8960, which is the next generation of the one for HTC One S. The wireless radio techniques for Snapdragon S4 has support for larger range of network types~\cite{snapdragon}. The detailed discussion about the hardware differences is out of the scope of this paper.

% RLC Loss ratio per RRC state
\begin{figure}[t!]
\centering
\includegraphics[width=0.5\textwidth]{figs/rlc_retx_udp.eps}
\ncaption{Significant RLC retransmission ratio over stable FACH state and FACH promotion state strongly implies the upper layer latency during the beginning part of the data transmission}
\label{fig:RLC.Loss.Per.RRC.UDPTrace}
\end{figure}

%TCP Trace Analysis
We also examined performance in TCP. A \textit{retransmission timeout} (RTO) in TCP can cause RTT delay due to the resulting decrease in congestion window size and due to falling back to the slow start phase~\cite{tcp.rto}. We use our mapping algorithm to correlate TCP retransmission behavior with RLC retransmissions. We found that the current RLC protocol responds sluggisly to the duplicate ACKs that signal that a ODU has been lost (see Figure~\ref{fig:RLC.Dup.Ack}. This leads to a TCP RTO which introduces more latency in the transport layer.  

According to the 3GPP RLC specification, the sender only retransmits the PDU once it receives a STATUS LIST (i.e, non-acknowledged) control PDU from the receiver, ignoring duplicate ACKs~\cite{spec-3G-RLC}. These duplicate ACKs are strong hints for PDU losses. If the lost RLC PDUs were to be transmitted after 0.5s rather than 2.8s, then the TCP RTO could be avoided, reducing latency by more than 2.3s. We propose a RLC \textit{Fast Re-Tx} mechanism, where unacknowledged PDUs are retransmitted once three duplicate RLC PDU ACKs are received by the sender. The resulting faster reaction to lost signals would reduce both RLC latency and latency in the transport layer.

%The TCP retransmission timeout (RTO) could cause apparent round trip delay due to congestion window drop by half and restarting the data transmission from the slow start phase~\cite{tcp.rto}. From the \emph{QxDM\_{}Trace}, we correlate the TCP retransmission behavior with the RLC retransmission through our mapping algorithm. By capturing the root cause of the TCP RTO, we found that current RLC protocol has a sluggish response to the PDU lost sigals -- the duplicate ACKs, in Figure~\ref{fig:RLC.Dup.Ack}. The delayed RLC retransmission PDUs leads TCP RTO, which further introduces latency in the transport layer. In 3GPP RLC specification, the sender only retransmits the PDU once it receives the STATUS LIST (or non-acknowledged) control PDU from the receiver, but ignores to duplicate ACKs, which is a strong hint for PDU loss~\cite{spec-3G-RLC}. If we could bring the group of retransmitted RLC PDUs from 2.8 s to 0.5 s, then we could avoid TCP RTO, reducing the latency more than 2.3 s. Therefore, we propose a RLC \textit{Fast Re-Tx} mechanism, which will retransmit the unacknowledged PDUs once the sender receives three duplicate RLC PDU ACKs. The faster reaction to loss signals could reduce RLC layer latency and further reduce the latency in transport layer.

% explain the root cause of the longer delay analysis
\begin{figure}[t!]
\centering
\includegraphics[width=0.5\textwidth]{figs/rlc_dup_ack.eps}
\ncaption{Two Latency Causes: short DCH demotion timer and lagging response to the PDU lost signal}
\label{fig:RLC.Dup.Ack}
\end{figure}

% UDP loss analysis
%\subsubsection{Root Cause of Packet Loss}\label{sec:udp.loss.analysis}
Finally, we examine UDP losses in each RRC state and identify root causes of these losses.  We label each packet with a unique ``sequence number" to map UDP packets sent from the client to the server-side tcpdump trace --- a loss occurs when a packet never appears at the server.  We consider the RRC state associated with each packet to be that when then packet is sent, and again treat promotion and initialization periods separately.  Packet loss ratios are the ratios between the number of packets lost from each state and those sent.  AS can be seen in Figure~\ref{fig:udp.loss}, these losses are highly device-dependent as well, with the HTC One having a higher loss ratio in DCH and FACH, and the Samsung Galaxy S3 being more lossy in PCH.  As devices will perform most transmissions in DCH and FACH, the Galaxy S3 is less lossy overall.

%UDP protocol doesn't guarantee the data package delivery, because the sender doesn't receive feedback from the receiver. We are interested in understanding the UDP loss behaviors over each RRC state, and also identify the root cause of UDP packet loss. As we instrument a unique "sequence number" for every UDP packet in \emph{QxDM\_{}TRACE}, we are able to apply the one-to-one mapping of UDP packet from client side \emph{QxDM\_{}TRACE} to the server side tcpdump trace. Each packet loss is considered as an packet appeared on the client side, but not on the server side. The RRC state of a packet means the state when it was transmitted. The packet loss ratio per RRC state is calculated as the number of packets get lost over that state divided by the total number of packets over that state. In Figure~\ref{fig:udp.loss}, the loss ratio really depends on the devices. HTC One S has a higher loss ratio over, DCH, and FACH state. While Samsung Galaxy S3 is more lossy over the PCH state. As the device is generally stay in DCH and FACH state, the Galaxy S3 will be less loss than the HTC device.

% UDP Loss Ratio plot
\begin{figure}[t!]
\centering
\includegraphics[width=0.5\textwidth]{figs/udp_loss.eps}
\ncaption{UDP loss is device dependent and RRC state dependent}
\label{fig:udp.loss}
\end{figure}

To identify the root cause of these UDP losses, we use the cross layer mapping algorithm to understand RLC-layer behavior.  We wish to understand if the UDP packets are getting lost in the cellular network or in the internet.  According to the 3GPP specification~\cite{spec-3G-RLC}, RCL PDUs are lost between the handset and the Node-B due either to senders retransmitting the PDUs more times than a pre-defined limit or due to the sender being reset by the receiver.  After mapping each UDP PDU with the corresponding RLC PDU, we check if the sender received a reset control PDU from the receiver or if the number of retransmitted PDUs exceed a predefined limit.  If neither case applies, the UDP packet was lost over the internet.  Figure~\ref{fig:udp.loss.root.cause} shows that most UDP packets are lost over the internet.  The RLC layer ARQ (Automatic Repeat reQuest) mechanism limits losses in the RCL layer.

%To identify the root cause of the UDP loss, we apply the cross layer mapping algorithm, and analyze the RLC layer behaviors. We are interested in whether the UDP packets get lost in the cellular network or in the internet. Based on 3GPP specificaiton~\cite{spec-3G-RLC}, RLC PDUs will be lost in between the handset and the Node-B, because either the sender retransmit the PDU more than a pre-defined limit or the sender was reset by the receiver. After map each UDP packet with a corresponding RLC PDUs, we will check whether the sender received a reset control PDU from the receiver, or the number of retransmitted PDU exceeding the pre-defined limit. The rest of the cases would count as the UDP lost over the internet. In Figure~\ref{fig:udp.loss.root.cause}, most of the UDP packets are lost over the internet, which is primarily because the RLC layer ARQ (Automatic Repeat reQuest) mechanism in the RLC layer. 

% UDP Loss Root Cause
\begin{figure}[t!]
\centering
\includegraphics[width=0.5\textwidth]{figs/udp_loss_root_cause.eps}
\ncaption{The major loss cause of UDP packets comes from internet, but not in the cellular network}
\label{fig:udp.loss.root.cause}
\end{figure}


\subsection{Public Deployment}\label{sec:largescalestudy}

To get a broader and more representatitve set  of data, we integrated the coarse-grained RTT measurement functionality into Mobiperf~\cite{mobiperf}, an existing network performance measurement application.  We collected incomplete sets of RTT data and aggregated the results (as opposed to the internally-used application, which measures an entire set of tests all at once). We also collected data points from 0 to 20 second inter-packet intervals, rather than 0 to 15 seconds as we did for our controlled study. We did not collect data on the impact of RRC state on higher-level protocols, however.

We collected data 130 distinct devices on 41 carriers in 25 countries, based on hashed phone identifiers (to preserve user anonymity).  However, there are two subsets of this data set we exclude.  First, a number of devices (48 in total) never completed sufficient tests.  We exclude devices which ran less than three tests comprising at least 25 data points each. Second, a number of devices never uploaded accurate data on the network technology used --- either because they never updated from the original application version that did not collect this data, or because their device always returns the value "UNKNOWN". We exclude these devices from any findings that require knowing the specific network technology.   We therefore focus on 27 devices with complete data in this section --- these cover 9 countries, 16 carriers and 20 distinct device models from six manufacturers.  

%such as the US, Germany, the UAE, Indonesia and China.  Phone identifiers were hashed to preserve user anonymity.  Because of the incomplete data provided by devices in the public test, N devices never uploaded sufficient data to perform the RRC inference task.  N devices had their RRC model flagged as ``anomalous" and after a manual inspection were disregarded due to having insufficient data.
%TODO fill in numbers

First, we examine the inferred RRC states for the devices for which data has been collected and examine how they vary across carriers.  For LTE, we had data on 
%The results are summarized in Table~\ref{tab:rrc_state_table}.  
As can be seen in Figure~\ref{fig:timer_cdf}, certain timers are particularly common. There are a limited number of different RRC state machines that seem to be implemented in practice, even accross very different carriers, and this is especially true for LTE.  Timers of 6-7 seconds for LTE seem to be most common, although in the US timers of 10 seconds were frequently observed. For 3G, there is far more variation, but usually devices fall back to FACH within 2.5 to 4.5 seconds.  FACH can last from 3-5 seconds, with lower values being far more common.

We have only a small number of devices for most carriers, making it difficult to determine if the RRC state machine differs for that carrier by device or location.  However, there is data on several major US carriers for different locations and devices.  The inferred RRC timers are almost always the same for a given carrier and network technology within half a second.

%For most carriers, we have only a small number of devices per carrier, and so it is difficult to determine if the RRC state machine for a specific carrier varies by device or location.  However, for several major US carriers we had a number of different users accross the country.  For example, for AT\&T, we collected data from users in Michigan, California, Pensylvania, and Florida.  The inferred timers for each network technology are almost always consistent accross these geographic regions, within half a second.  The one exception is Verizon ---  we observed two different LTE timers in two different geographic locations with the same model of phone.  

UMTS allows variation both in the timers between states and in the states available.  As was shown in previous work, some carriers will skip the FACH state either when promoting or demoting\cite{3g_rrc}. We found five distinct 3G RRC state machines that always pass through FACH in both directions, and six that do not enter FACH when promoting from IDLE.  Four additional carriers had the FACH state entirely obscured by the FACH\_{}TRANSITION effect. In those cases it is unclear if FACH is ever entered, but users would not benefit from FACH. Additionally, ten devices did not upload carrier information. Eight entered FACH in both directions, and two did not enter FACH during state promotion.  Most carriers within the US have state machines that enter FACH in both directions, aside from Verizon which exhibited both patterns.  No other RRC state machine patterns were observed.

%, specifically, allows more variation in how it is implemented. As was shown in previous work, some carriers will, upon recieving a packet in IDLE, go directly to DCH regardless of the size of the packet, whereas others might first pass through FACH~\cite{3g_rrc}.  In our survey of carriers, we found five distinct RRC state machines that always pass through FACH whether promoting or demoting, and six that do not enter FACH when promoting from IDLE.  There were four additional RRC state machines where data was sufficiently noisy that a significant number of measurements taken were ambiguous; three of these had the majority of their measurements consistent with entering FACH in both scenarios.  Additionally, eight devices which lacked carrier information entered FACH in both directions, and two did not enter FACH when promoting.

%Single-directional FACH state machines were most common outside of the US; additionally, Verizon exhibited both patterns on different devices.  We did not observe any other RRC state machine patterns. 
Overall, there is a reasonable amount of variation in how RRC states are implemented among carriers, but certain state machines are more common than others.

There is an unexplained, but consistent delay in the middle of FACH for a major UK carrier. We have only one device using that carrier, but the delay has occurred consistently for 23 different tests. Further investigation would be required to determine the root cause of the delay.

Delays during FACH\_{}TRANSITION were common, and appeared to depend on the device model and not the carrier, although in relatively few cases were we able to compare different device models on the same carrier and with the same network technology. All of the HTC models, half of the Samsung models, exhibited this behavior, and the single Motorola model we observed did not. Overall, two thirds of device models experience this delay.   Similar trends can be seen in LTE for delays relating to the transition from RRC\_CONNECTED to RRC\_IDLE. In figure~\ref{fig:device_compare} we show how latencies and packet losses differ for two devices on the same carrier and using the same underlyiing RRC state transition timers.


\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.45\textwidth]{figs/all_carrier_timers.png}
\end{center}
\ncaption{CDF of RRC 3G timers, for distinct RRC state machines.}
\label{fig:timer_cdf}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.5\textwidth]{figs/device_compare.png}
\end{center}
\ncaption{RTTs and loss rates for an HTC One and Samsung S3 device on the same T-mobile LTE network.  Note that only the HTC device exhibits an additional delay around state demotion.}
\label{fig:device_compare}
\end{figure}

We also examined the average promotion delays associated with different RRC states, as shown in Figure~\ref{fig:all_carrier_rrc_delays}.  As most of our data was for LTE or UMTS, we focus on these two technologies.  We see that the pattern we observed on the for T-mobile dataseta holds here as well, although it appears that in general FACH does exhibit a performance improvement.  Part of this, however, is due to the fact that carriers where FACH occurs perform better in general. It can be seen that even for large packets FACH performs better on average than PCH, although for a specific RRC state machine the performance for large packets should be the same.  It can also be seen that the performance impact of the LTE anomalous transition behavior is far less than that in 3G, and that RRC\_{}IDLE for LTE varies enormously in how well it performs.  This variation is an expected effect of discontinous reception (DRX) in RRC\_{}IDLE.

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.45\textwidth]{figs/all_carrier_rrc_delays.png}
\end{center}
\ncaption{Promotion delays for each state for all carriers surveyed}.
\label{fig:all_carrier_rrc_delays}
\end{figure}

We also examined trends in packet losses in different RRC states for these carriers, as shown in Figure~\ref{fig:loss_compare}, again comparing 3G and LTE.  Unsurpisingly losses are generally low in high-power states (DCH or RRC\_{}CONNECTED) and are high in low-power states. This is especially true in LTE. As we found with our QxDM measurements, losses during FACH\_{}TRANSITION, and even in FACH in general, are also quite high.

%\comment{Why are losses higher for smaller packets? Is this expected behavior?}

%\comment{If time permits perform this analyis for our T-mobile data set, however due to the database problems this sort of analysis may be more time-consuming to do (as I'm currently parsing a giant dump of the database contents)}



%\comment{I suspect this occurs more when we get the bad FACH behavior, would be good to verify}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.45\textwidth]{figs/loss_compare.png}
\end{center}
\ncaption{Packets lost per state, as a fraction.  Note that LTE data is rather limited.}
\label{fig:loss_compare}
\end{figure}

Overall, it can be seen that the phenomena we have observed in our controlled experiments on T-Mobile devices are of more universal relevance, and more generally that our client-based inference methodology is an effective way to understand trends in RRC state implementations and performance more broadly.   Our inference technique has additionally allowed us to understand the performance characteristics of networks on consumer devices, without requiring any expert knowledge to collect the needed data.



%\comment{Tmobile timers consistent.  Only variation is FACH noise for UMTS.  EDGE: timer 1.5s, no FACH-like state.  HSDPA: only one data point, timer 3s, no FACH.  LTE: timer 2s, one data point and kind of noisy (but collecting data on a second data point).  UMTS: 2.5s timer for DCH and another 2.5 on FACH, often eaten by demotion-related delay.}



%\begin{figure}[t!]
%\begin{center}
%\includegraphics[width=0.45\textwidth]{figs/placeholder.png}
%\end{center}
%\ncaption{Performance for each device for T-mobile only; colour-code by geographic state - TODO - not much interesting data? lower priority}
%\label{fig:fach_demotion_delay_prevalence}
%\end{figure}
