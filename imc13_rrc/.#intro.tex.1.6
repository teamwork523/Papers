\section{Introduction}
%\renewcommand{\labelitemii}{$\star$}

\begin{itemize}

Cellular network technologies, such as 3G UMTS and 4G LTE, transition between various Radio Resource Control (RRC) states based on the network traffic patterns of individual mobile clients.  These states have different performance and energy consumption tradeoffs, as well as different overheads to transition between them, and they exist in order to allow users to experience good network performance on resource-constrained devices. Although the general pattern of acceptable RRC states and transitions between them are defined by an external specification, different carriers have different implementations of these states, and in particular of the timers for when devices transition between them. We also find that the performance characteristics of these states can differ both by device and by location.  The real-world implementation of RRC state machines and the impact on performance is not well-understood.

In this paper, we examine how RRC states are implemented and their real-world state-transition behavior and impact on performance at several levels, and in doing so uncover several previously unknown phenomena that affect user performance.  We perform a large-scale study of RRC state implementations and performance on N carriers from N countries, as well as an extensive, in-depth study of RRC performance on a number of controlled devices, including a cross-layer analysis to understand the root causes of the phenomena we detect by examining behavior at the Radio Link Control (RLC) layer.

We present three main types of contributions. First, we present several methodological contributions which allow us to perform measurements that lead to a deeper understanding of RRC behavior. Second, we present our findings on previously unknown performance problems and phenomena. Third, we disucss the implications of our findings and suggest some potential performance optimizations. 

For our methodological contributions, we design a generic RRC state model generation method that is robust to poor network conditions and interfering background traffic in order to allow for a large-scale study of RRC state machines by non-expert users on arbitrary mobile devices. We also develop a method of measuring timers less than a second in length (such as the DRX timers in LTE) which have previously not been measurable using network traffic. Additionally, we develop a novel cross-layer mapping mechanism to correlate transport layer packets with data layer link PDUs so that the root causes of TCP and UDP performance issues can accurately be identified at the RLC layer. This allows 99.8\% of the transport layer packets to be mapped to the corresponding RLC layer PDUs.

For our second set of contributions, we present several new findings.  Among other things, we detect widespread performance problems where certain demotion patterns result in significant latencies on a specific mobile handset models. We show that, globally, there are a limited number of very similar RRC state machines implemented, which may have implications for any RRC state based application optimization approach.  At the RLC layer, we observe frequent RLC-layer retransmission delays around the FACH state and around promotions to FACH state, which contributes to the transport layer latency. These findings both show that there are significant performance problems that were previously undetected as well as show that our methods are useful tools for understanding how RRC states perform and are implemented in the real world.

Finally, we propose an improvement to how RLC currently behaves based on our findings. To avoid extra retransmissions that occur during the poorly-performing FACH state and FACH-state transitions observed, the application could batch the data transmission to reduce the possible number of transmissions in these states.  To address this RLC retransmission delay issue, we propose a RLC \emph{Fast Re-Tx} mechanism that actively responds to the RLC PDU loss signals. By simulating this fast retransmission mechanism using real QXDM traces, we apply a cost-benefit analysis and find that \emph{Fast Re-Tx} could reduce RLC latency by up to 35.69\% when these poorly-performing FACH states occur. 

% TODO fill in N


%%	\begin{itemize}
%		\item
%			\textbf{Methodology:} Based on state of art RRC state inference method, we designed a generic RRC state model generation mechanism to effectively reduce the effect of unstable wireless channel, and produce finer RRC state machine using classic statistical method. In additional, we develop the first cross layer mapping mechanism in the empirical study to correlate the transport layer packets with the data layer link PDUs, so that we could accurately identify the TCP/UDP performance issue inside the RLC layer. We could map 99.8\% of the transport layer packets to the corresponding RLC layer PDUs.
%		\item
%			\textbf{Observation:} We observe the abnormal large FACH state latency issue through our RRC inference measurement. After a world wide scale deployment of RRC state model generation measurement, we are able to discover the device dependent and network specific abnormal FACH state behaviors. We also observe the frequent RLC layer retransmission and retransmission delay over initial FACH state and FACH promotion transition, which contributes a lot to the transport layer latency.
%		\item	
%			\textbf{Implications:} Due the abnormal initial FACH state and FACH latency behavior, the application could batch the data transmission to reduce the possible number of transmission over FACH. To address the RLC retransmission delay issue, we propose a RLC \emph{Fast Re-Tx} mechanism to active response to the RLC PDU loss signals. By simulate the fast retransmission mechanism in the real trace QxDM, we apply cost-benefit analysis and found that \emph{Fast Re-Tx} could reduce RLC latency up to 35.69\% over FACH states.
%	\end{itemize}
